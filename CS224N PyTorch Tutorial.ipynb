{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bitdribble/cs224n/blob/main/CS224N%20PyTorch%20Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "perceived-donor",
      "metadata": {
        "id": "perceived-donor"
      },
      "source": [
        "# CS224N: PyTorch Tutorial (Winter '21)\n",
        "\n",
        "Author: Dilara Soylu\n",
        "\n",
        "In this notebook, we will have a basic introduction to PyTorch and work on a toy NLP task. Following resources have been used in preparation of this notebook:\n",
        "\n",
        "* [Word Window Classification](https://web.stanford.edu/class/cs224n/materials/(https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1204/materials/ww_classifier.ipynb) tutorial notebook by Matt Lamm, from Winter 2020 offering of CS224N\n",
        "* Official PyTorch Documentation on [Deep Learning with PyTorch: A 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) by Soumith Chintala\n",
        "* PyTorch Tutorial Notebook, [Build Basic Generative Adversarial Networks (GANs) | Coursera](https://www.coursera.org/learn/build-basic-generative-adversarial-networks-gans) by Sharon Zhou, offered on Coursera\n",
        "\n",
        "Many thanks to Angelica Sun and John Hewitt for their feedback."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "static-african",
      "metadata": {
        "id": "static-african"
      },
      "source": [
        "## Introduction\n",
        "[PyTorch](https://pytorch.org/) is a machine learning framework that is used in both academia and industry for various applications. PyTorch started of as a more flexible alternative to [TensorFlow](https://www.tensorflow.org/), which is another popular machine learning framework. At the time of its release, `PyTorch` appealed to the users due to its user friendly nature: as opposed to defining static graphs before performing an operation as in `TensorFlow`, `PyTorch` allowed users to define their operations as they go, which is also the approached integrated by `TensorFlow` in its following releases. Although `TensorFlow` is more widely preferred in the industry, `PyTorch` is often times the preferred machine learning framework for researchers. \n",
        "\n",
        "Now that we have learned enough about the background of `PyTorch`, let's start by importing it into our notebook. To install `PyTorch`, you can follow the instructions here. Alternatively, you can open this notebook using `Google Colab`, which already has `PyTorch` installed in its base kernel. Once you are done with the installation process, run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hindu-wales",
      "metadata": {
        "id": "hindu-wales"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Import pprint, module we use for making our print statements prettier\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adjacent-hearing",
      "metadata": {
        "id": "adjacent-hearing"
      },
      "source": [
        "We are all set to start our tutorial. Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors\n",
        "Tensors are the most basic building blocks in `PyTorch`. Tensors are similar to matrices, but the have extra properties and they can represent higher dimensions. For example, an square image with 256 pixels in both sides can be represented by a `3x256x256` tensor, where the first 3 dimensions represent the color channels, red, green and blue.\n",
        "\n",
        "## Tensor Initialization\n",
        "\n",
        "There are several ways to instantiate tensors in `PyTorch`, which we will go through next.\n",
        "\n",
        "### From a Python List\n",
        "\n",
        "We can initalize a tensor from a `Python` list, which could include sublists. The dimensions and the data types will be automatically inferred by `PyTorch` when we use `torch.tensor()`.\n",
        "\n"
      ],
      "metadata": {
        "id": "RL1gE6Esvqxh"
      },
      "id": "RL1gE6Esvqxh"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a tensor from a Python List\n",
        "data = [\n",
        "        [0, 1], \n",
        "        [2, 3],\n",
        "        [4, 5]\n",
        "       ]\n",
        "x_python = torch.tensor(data)\n",
        "\n",
        "# Print the tensor\n",
        "x_python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydv-uB0EwNKg",
        "outputId": "496dc5f5-61c9-4f56-963f-a8d5fdc1ecb0"
      },
      "id": "Ydv-uB0EwNKg",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [2, 3],\n",
              "        [4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also call `torch.tensor()` with the optional `dtype` parameter, which will set the data type. Some useful datatypes to be familiar with are: `torch.bool`, `torch.float`, and `torch.long`."
      ],
      "metadata": {
        "id": "W9ADRDOYwaUU"
      },
      "id": "W9ADRDOYwaUU"
    },
    {
      "cell_type": "code",
      "source": [
        "# We are using the dtype to create a tensor of particular type\n",
        "x_float = torch.tensor(data, dtype=torch.float)\n",
        "x_float"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdLNaxp7wZ1o",
        "outputId": "0370f80c-dcc5-442c-b357-86e36694af92"
      },
      "id": "CdLNaxp7wZ1o",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [2., 3.],\n",
              "        [4., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We are using the dtype to create a tensor of particular type\n",
        "x_bool = torch.tensor(data, dtype=torch.bool)\n",
        "x_bool"
      ],
      "metadata": {
        "id": "QcVlGoUfxCR5",
        "outputId": "d889ac80-7431-415c-b08e-0dd979268209",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QcVlGoUfxCR5",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True],\n",
              "        [ True,  True],\n",
              "        [ True,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also get the same tensor in our specified data type using methods such as `float()`, `long()` etc.\n"
      ],
      "metadata": {
        "id": "ufU9ifg-xFEE"
      },
      "id": "ufU9ifg-xFEE"
    },
    {
      "cell_type": "code",
      "source": [
        "x_python.float()"
      ],
      "metadata": {
        "id": "ShBsOI2KxKNd",
        "outputId": "9e74ce29-7f90-4db7-dfab-a5043549d472",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ShBsOI2KxKNd",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [2., 3.],\n",
              "        [4., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use `tensor.FloatTensor`, `tensor.LongTensor`, `tensor.Tensor` classes to instantiate a tensor of particular type. `LongTensors` are particularly important in NLP as many methods that deal with indices require the indices to be passed as a `LongTensor`, which is a 64 bit integer."
      ],
      "metadata": {
        "id": "GaKsaYAmxRwX"
      },
      "id": "GaKsaYAmxRwX"
    },
    {
      "cell_type": "code",
      "source": [
        "# `torch.Tensor` defaults to float\n",
        "# Same as torch.FloatTensor(data)\n",
        "x = torch.Tensor(data) \n",
        "x\n"
      ],
      "metadata": {
        "id": "9obQghdaxav1",
        "outputId": "a22e6345-1527-4060-f3bd-467b2df9ee40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9obQghdaxav1",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [2., 3.],\n",
              "        [4., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From a NumPy Array\n",
        "\n",
        "We can also initialize a tensor from a `NumPy` array.\n"
      ],
      "metadata": {
        "id": "PWW69PNBxqKY"
      },
      "id": "PWW69PNBxqKY"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize a tensor from a NumPy array\n",
        "ndarray = np.array(data)\n",
        "x_numpy = torch.from_numpy(ndarray)\n",
        "\n",
        "# Print the tensor\n",
        "x_numpy"
      ],
      "metadata": {
        "id": "ZqZiTdGdxwAA",
        "outputId": "462801a0-2f42-46b5-c0ba-0e5d218886e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZqZiTdGdxwAA",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [2, 3],\n",
              "        [4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From a Tensor\n",
        "\n",
        "We can also initialize a tensor from another tensor, using the following methods:\n",
        "\n",
        "* `torch.ones_like(old_tensor)`: Initializes a tensor of 1s.\n",
        "* `torch.zeros_like(old_tensor)`: Initializes a tensor of 0s.\n",
        "* `torch.rand_like(old_tensor)`: Initializes a tensor where all the elements are sampled from a uniform distribution between 0 and 1.\n",
        "* `torch.randn_like(old_tensor)`: Initializes a tensor where all the elements are sampled from a normal distribution.\n",
        "\n",
        "All of these methods preserve the tensor properties of the original tensor passed in, such as the shape and device, which we will cover in a bit.\n"
      ],
      "metadata": {
        "id": "bpA0rqdMx21A"
      },
      "id": "bpA0rqdMx21A"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a base tensor\n",
        "x = torch.tensor([[1., 2.], [3., 4.]])\n",
        "x"
      ],
      "metadata": {
        "id": "80racMnux15m",
        "outputId": "9cebf356-2141-481f-f3b0-bcb9c6bf6eac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "80racMnux15m",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a tensor of 0s\n",
        "x_zeros = torch.zeros_like(x)\n",
        "x_zeros"
      ],
      "metadata": {
        "id": "Io-_JxXLyIZu",
        "outputId": "ccd210da-bdaf-4877-9580-9aa0bec4703d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Io-_JxXLyIZu",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a tensor of 1s\n",
        "x_ones = torch.ones_like(x)\n",
        "x_ones"
      ],
      "metadata": {
        "id": "QMp3wyilyLNN",
        "outputId": "ec818563-f697-4540-94f4-4a6cb9e356a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QMp3wyilyLNN",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a tensor where each element is sampled from a uniform distribution\n",
        "# between 0 and 1\n",
        "x_rand = torch.rand_like(x)\n",
        "x_rand"
      ],
      "metadata": {
        "id": "ivIvo-MgyOeF",
        "outputId": "64a8c447-90bc-46f5-a00f-21e86b346f34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ivIvo-MgyOeF",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3386, 0.0887],\n",
              "        [0.6176, 0.8548]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a tensor where each element is sampled from a normal distribution\n",
        "x_randn = torch.randn_like(x)\n",
        "x_randn"
      ],
      "metadata": {
        "id": "Pt2yxHrHyPeJ",
        "outputId": "37ec01d2-cc29-4bd5-a46c-db0c74eaec96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Pt2yxHrHyPeJ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0035, -0.6282],\n",
              "        [-0.5455,  1.5023]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### By Specifying a Shape\n",
        "\n",
        "We can also instantiate tensors by specifying their shapes (which we will cover in more detail in a bit). The methods we could use follow the ones in the previous section:\n",
        "\n",
        "* `torch.zeros()`\n",
        "* `torch.ones()`\n",
        "* `torch.rand()`\n",
        "* `torch.randn()`"
      ],
      "metadata": {
        "id": "JJqOu9l-yZRt"
      },
      "id": "JJqOu9l-yZRt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a 2x3x2 tensor of 0s\n",
        "shape = (4, 2, 2)\n",
        "x_zeros = torch.zeros(shape) # x_zeros = torch.zeros(4, 3, 2) is an alternative\n",
        "x_zeros"
      ],
      "metadata": {
        "id": "ggaIEp1vyTm5",
        "outputId": "380f1541-d7b2-456b-9e2f-73be95bb335b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ggaIEp1vyTm5",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With torch.arange()\n",
        "\n",
        "We can also create a tensor `with torch.arange(end)`, which returns a 1-D tensor with elements ranging from `0` to `end-1`. We can use the optional start and step parameters to create tensors with different ranges.\n"
      ],
      "metadata": {
        "id": "SF9waHgjypNS"
      },
      "id": "SF9waHgjypNS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with values 0-9\n",
        "x = torch.arange(10)\n",
        "x"
      ],
      "metadata": {
        "id": "eeJNV7t0ykU5",
        "outputId": "028a5ab6-0bc4-4c77-97eb-647fd90d4af8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "eeJNV7t0ykU5",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Properties\n",
        "\n",
        "Tensors have a few properties that are important for us to cover. These are namely shape, and the device properties.\n",
        "\n",
        "### Data Type\n",
        "\n",
        "The `dtype` property lets us see the data type of a tensor.\n"
      ],
      "metadata": {
        "id": "7QdI-QD9y6GB"
      },
      "id": "7QdI-QD9y6GB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a 3x2 tensor, with 3 rows and 2 columns\n",
        "x = torch.ones(3, 2)\n",
        "x.dtype"
      ],
      "metadata": {
        "id": "v_cf5ODay2Dn",
        "outputId": "f769eb58-8b10-4b96-d72d-c1c73b7d0dfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "v_cf5ODay2Dn",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shape\n",
        "\n",
        "The `shape` property tells us the shape of our tensor. This can help us identify how many dimensional our tensor is as well as how many elements exist in each dimension.\n"
      ],
      "metadata": {
        "id": "aMP7hU9WzEk1"
      },
      "id": "aMP7hU9WzEk1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a 3x2 tensor, with 3 rows and 2 columns\n",
        "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
        "x"
      ],
      "metadata": {
        "id": "b5N8scDJzB7B",
        "outputId": "3ce09e6d-74af-44bf-b9af-7826568d5970",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "b5N8scDJzB7B",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out its shape\n",
        "# Same as x.size()\n",
        "x.shape "
      ],
      "metadata": {
        "id": "-4_6YuQSzKvn",
        "outputId": "91a67eca-65bc-44d1-ca03-e63bb2ed5884",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-4_6YuQSzKvn",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the number of elements in a particular dimension\n",
        "# 0th dimension corresponds to the rows\n",
        "x.shape[0]"
      ],
      "metadata": {
        "id": "qexAojPyzNI6",
        "outputId": "0b603b32-c4e9-4db0-e450-54f6f88f0c91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qexAojPyzNI6",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can change the shape of a tensor with the `view()` method."
      ],
      "metadata": {
        "id": "5H0x2OsbzVQS"
      },
      "id": "5H0x2OsbzVQS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Example use of view()\n",
        "# x_view shares the same memory as x, so changing one changes the other\n",
        "x_view = x.view(3, 2)\n",
        "x_view"
      ],
      "metadata": {
        "id": "2YKOaJeTzQyI",
        "outputId": "f359772a-f5d3-4e18-b774-c1b08a0f94b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2YKOaJeTzQyI",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can ask PyTorch to infer the size of a dimension with -1\n",
        "x_view = x.view(-1, 3)\n",
        "x_view"
      ],
      "metadata": {
        "id": "1rEx1oeMzbqt",
        "outputId": "104c0537-ea99-4eef-f314-1eab477c19e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1rEx1oeMzbqt",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use `torch.reshape()` method for a similar purpose. There is a subtle difference between `reshape()` and `view()`: `view()` requires the data to be stored contiguously in the memory. You can refer to this StackOverflow answer for more information. In simple terms, contiguous means that the way our data is laid out in the memory is the same as the way we would read elements from it. This happens because some methods, such as `transpose()` and `view()`, do not actually change how our data is stored in the memory. They just change the meta information about out tensor, so that when we use it we will see the elements in the order we expect.\n",
        "\n",
        "`reshape()` calls `view()` internally if the data is stored contiguously, if not, it returns a copy. The difference here isn't too important for basic tensors, but if you perform operations that make the underlying storage of the data non-contiguous (such as taking a `transpose`), you will have issues using `view()`. If you would like to match the way your tensor is stored in the memory to how it is used, you can use the `contiguous()` method.\n"
      ],
      "metadata": {
        "id": "3afORlMazu9c"
      },
      "id": "3afORlMazu9c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the shape of x to be 3x2\n",
        "# x_reshaped could be a reference to or copy of x\n",
        "x_reshaped = torch.reshape(x, (2, 3))\n",
        "x_reshaped"
      ],
      "metadata": {
        "id": "Ciq-uDGL0BSU",
        "outputId": "662dad27-6a7c-492e-a864-e52b65f394ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ciq-uDGL0BSU",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MLJ7dGe30B6_"
      },
      "id": "MLJ7dGe30B6_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs224n",
      "language": "python",
      "name": "cs224n"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "CS224N PyTorch Tutorial.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}